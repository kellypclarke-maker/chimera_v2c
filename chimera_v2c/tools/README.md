# Tools Overview (Active Only)

All tools must be documented here. Anything not listed is treated as legacy and should not be used in production; if it is intentionally revived, retrieve it from git history and document it here with clear overwrite safeguards.

## Core Daily Flow
- `refresh_slate_updates.py` — Mandatory preflight: pulls ESPN injuries (player-level) + team-filtered news for the slate (nba|nhl|nfl), writes `chimera_v2c/data/raw_injuries.json`, `chimera_v2c/data/raw_news.json`, and a digest `chimera_v2c/data/news_<date>_<league>.txt` (also mirrored into `reports/llm_packets/<league>/<YYYYMMDD>/news.txt`). Ensures `chimera_v2c/data/injury_adjustments.json` has per-team entries for the slate date without overwriting existing non-zero deltas. `run_daily.py`, `log_plan.py`, and `execute_plan.py` auto-run this step unless `--skip-preflight` is passed.
- `run_daily.py` — Plan the slate (stats + market ensemble) for a given date/league. Uses Kalshi **public** markets by default (`execution.use_private: false`); only uses private/trading API when `use_private: true` and private creds are present. Supports `--llm-injuries` to apply LLM-derived injury deltas (from the ESPN digest) before planning.
- `log_plan.py` — Persist plan log rows (per market side) to `reports/execution_logs/v2c_plan_log.json` for analysis/backtests. Includes `league`, `selected`, and `stake_fraction` fields; supports `--llm-injuries` to apply LLM-derived injury deltas (from the ESPN digest) before logging.
- `auto_rule_a_tminus_llm.py` — Automated T-minus (default ~T-30) LLM runner for Rule A: filters to games in a narrow minutes-to-start window where Kalshi currently favors home (home mid > 0.50), calls GPT/Gemini (if keys present), and writes HELIOS-formatted raw reports under `reports/specialist_reports/raw_auto/`. With `--apply`, it ingests those raw files to write canonical reports and fill blank/`NR` daily-ledger model cells (append-only; respects lockfiles).
- `run_rule_a_daily.py` — Safe wrapper for the taker-only Rule A workflow: creates plan CSVs and reconciles fills/grades into execution logs; by default writes only under `reports/execution_logs/` and never overwrites daily ledgers (planning uses `--allow-empty` and reconciliation skips grading empty plans).
- `append_rule_a_execution_log_from_fills.py` — Append `export_kalshi_fills.py` output into `reports/execution_logs/rule_a_execution_log.csv` so Rule A graders can backfill fills without manually pointing at per-day fills files (read-only wrt ledgers).
- `write_rule_a_research_queue.py` — Write a pre-filtered “research queue” (Kalshi home-favored only) and a copy/paste prompt pack for manual LLM runs; does not call any LLM APIs.
- `build_rule_a_maker_order_sheet.py` — Build a maker-only CSV order sheet from the latest per-league Rule A votes plan CSVs (no trading; output only). Intended for human/manual execution; includes each game’s vote models and a computed maker limit price clamped to `ask-1`.
- `print_rule_a_order_commands.py` — Print copy/paste commands from a Rule A maker order sheet. Default output is dry-run commands; pass `--live` to print commands that include `--confirm` (real trades).
- `kalshi_place_limit_order.py` — Place a single Kalshi limit order using private creds (real trades). Defaults to dry-run unless `--confirm` is passed. Optional `--require-maker` checks the current YES ask (via private markets) and aborts if your limit would cross.
- `place_rule_a_maker_orders_from_sheet.py` — Batch place all maker orders from a Rule A maker order sheet (real trades). Defaults to dry-run unless `--confirm` is passed; optional `--require-maker` skips any order that would cross the current YES ask.
- `report_rule_a_daily_curve.py` — Read-only: generate a day-by-day Rule A net PnL + ROI table over a date range using T-minus bid/ask snapshots (default T-30, away ask + 1¢ slippage, taker fees). Auto-loads per-league eligibility JSONs if present (or disable via `--no-eligibility`). Writes a CSV under `reports/thesis_summaries/`.
- `learn_rule_a_model_eligibility.py` — Read-only: learn per-league Rule A model eligibility (primary vs secondary) from history using bootstrap ROI lower bounds (`roi_lb90` = 10th percentile of bootstrapped ROI at 90% confidence). Primary votes always count; secondary votes count only when at least one primary also triggers. Writes `chimera_v2c/data/rule_a_model_eligibility_<league>.json` (or `--out`).
- `report_rule_a_hybrid_model_status.py` — Read-only: write a per-league table of model status (`primary|secondary|excluded`) with reasons and bootstrap ROI stats, based on `rule_a_vote_calibration_<league>.json` + `rule_a_model_eligibility_<league>.json`. Useful for confirming whether `market_proxy` / `moneypuck` are actually contributing under the current gates.
- `report_rule_a_model_only_baselines.py` — Read-only: per-model “no blind” Rule A backtest over a date window (each model places 1 contract only when its own vote/flip gates pass under the per-league vote calibration JSON). Writes `net_pnl`/`roi_net` by (league, model) under `reports/thesis_summaries/`.
- `execute_plan.py` — Execute maker-only orders (dry-run by default). Supports `--llm-injuries` to apply LLM-derived injury deltas (from the ESPN digest) before execution.
- `kalshi_ws_listener.py` — Stream Kalshi mids to `data/ws_mids.json` (overlay in planner).
- `fetch_injuries.py` — ESPN injuries fetcher; writes `data/injury_adjustments.json` and `data/raw_injuries.json`.
- `fetch_injuries_nhl.py` — ESPN HTML scrape fallback for NHL injuries (seed text; prefer LLM merge for impact sizing).
- `news_watcher.py` — Add manual notes/halts and optional injury deltas.
- `live_guardrails.py` — Thesis-breaker halts using live scoreboard context.
- `ingest_results.py` — Grade results for a date/league into reports.

## Ratings / Data Prep
- `etl_nba_history.py` — Build `data/chimera.db` with NBA games + team stats.
- `elo_builder.py` — Derive Elo ratings into `data/team_ratings.json` from DB (NBA).
- `elo_builder_nhl.py` — Derive Elo ratings into `data/team_ratings_nhl.json` from ESPN scoreboard (with decay).
- `train_ff_model.py` — Train Four Factors logistic model -> `data/ff_model.json`.
- `export_db_to_json.py` — Hydrate JSON bridge (`team_four_factors.json`, etc.) from DB.
- `prepare_data.py` — Quick NBA ratings refresh (season-based).
- `fetch_sharp_odds.py` — Ingest sharp odds into the DB.

## Ledgers (Append-Safe Only)
- `ensure_daily_ledger.py` — Step #1 each day; create daily ledger for today (header-only if empty). Never overwrites unless `--overwrite --force`.
- `seed_daily_ledger_from_espn_schedule.py` — Append missing (date,league,matchup) rows for a given date by pulling ESPN scoreboards (nba|nhl|nfl). Initializes probability-like columns to `NR` and leaves `actual_outcome` blank; respects `reports/daily_ledgers/locked/` unless `--force`.
- `fill_daily_ledger_from_plan.py` — Append-safe seeder: runs the v2c planner for a league/date and fills blank/`NR` `v2c` + `kalshi_mid` cells (adds missing rows with other probability-like columns initialized to `NR`; respects `reports/daily_ledgers/locked/` unless `--force`).
- `format_daily_ledger.py` — Canonical formatter: rewrites a *single date* ledger into the minimal, operator-readable schema (drops noisy columns, formats probabilities to `.85`, fills blank probability cells with `NR`, leaves `actual_outcome` blank until final), snapshots before writing; use `--force` to operate on locked days only with explicit human intent.
- `build_schedule_csv_from_espn.py` — Write/update `reports/thesis_summaries/<league>_schedule_*.csv` from ESPN scoreboards (read-only w.r.t. ledgers) so `audit_ledger_parity.py` can validate daily/master ledgers vs schedule and final scores.
- `export_market_baselines_compare.py` — Read-only exporter: recompute Kalshi `kalshi_mid` (candlestick T-minus) and sportsbook `market_proxy` (Odds API history T-minus) for games in daily ledgers and write a separate comparison CSV under `reports/market_snapshots/` (does not modify ledgers or master).
- `backfill_v2c_raw_from_plan_json.py` — Deprecated: v2c_raw is no longer part of the canonical daily-ledger schema; do not use in normal workflows.
- `build_daily_game_ledgers.py` — Historical backfill: write per-day ledger(s) from the archived master (e.g., 2025-11-19..2025-12-03). Uses lockfiles; overwrite requires `--overwrite --force` and snapshots the prior file.
- `build_model_wr_by_league.py` — Read-only accuracy/Brier summary by league and overall from `reports/daily_ledgers/*_daily_game_ledger.csv` -> `reports/daily_ledgers/model_wr_by_league.csv` (models: `v2c|gemini|grok|gpt|kalshi_mid|market_proxy|moneypuck`).
- `build_model_reliability_by_p_bucket.py` — Read-only reliability/Brier/EV summary by predicted p buckets for each model vs `kalshi_mid` from `reports/daily_ledgers/*_daily_game_ledger.csv` -> `reports/daily_ledgers/model_reliability_by_p_bucket.csv` (models: `v2c|gemini|grok|gpt|kalshi_mid|market_proxy|moneypuck`).
- `build_ev_summary_by_league.py` — Read-only EV vs Kalshi mid + Brier summary by league from daily ledgers -> `reports/daily_ledgers/ev_brier_by_league.csv`.
- `fill_missing_daily_outcomes.py` — Use ESPN scoreboards to fill blank `actual_outcome` cells in daily ledgers (final games only; does not touch probabilities). Defensively checks both the ledger date and date+1 scoreboards (late-night timezone edge), supports `--overwrite-existing` to correct non-blank outcomes to ESPN finals and clear non-final placeholders back to blank, respects lockfiles unless `--force`, and snapshots before writing.
- `build_master_ledger.py` — Derive the master ledger (`reports/master_ledger/master_game_ledger.csv`) from daily ledgers, snapshots, archived specialist/canonical CSVs, and plan logs. Daily ledgers are authoritative for their keys; snapshots the prior master before writing. By default it refuses to overwrite existing probability cells; if you intentionally corrected a daily ledger and need the master to reflect it, rerun with `--allow-overwrite-locked` (explicit human intent only). Also writes by-league views under `reports/master_ledger/by_league/` (NBA/NFL omit `moneypuck`).
- `build_game_level_ml_table.py` — Legacy: append/fill the historical master `reports/specialist_performance/game_level_ml_master.csv` for historical analysis only.
- `build_complete_game_ledger.py` — Legacy: filter the master to rows with v2c, Gemini, Grok, and market mids -> `game_level_ml_complete.csv`.
- `snapshot_game_level_ledger.py` — Legacy: snapshot the master ledger to `reports/specialist_performance/snapshots/`.
- `preflight_check.py` — Guardrail: ensure injuries are fresh and game start times are within 30 minutes before planning/execution.
- `rolling_calibration.py` — Non-destructive accuracy/Brier summary over the last N days of daily ledgers.
- `shadow_no_edge_log.py` — Shadow log of per-game diagnostics/reasons when no orders are placed (no quotes, low edge, guardrails).
- `apply_llm_injuries_v2.py` — LLM-based injury delta generator (safe merge into injury_adjustments.json); audits raw response to `reports/specialist_reports/raw/` and writes change logs/snapshots under `reports/injury_snapshots/`. Team codes are normalized via `team_mapper`.
- `apply_llm_nhl_injuries.py` — NHL-specific LLM injury deltas (goalie/role aware) into injury_adjustments.json (safe merge); audits raw response to `reports/specialist_reports/raw/` and writes change logs/snapshots under `reports/injury_snapshots/`. Team codes are normalized via `team_mapper`.
- `etl_nhl_factors.py` — Build NHL process factors (xGF%, HDCF%, PP/PK z-scores, goalie rating, oi_sh%) from local CSVs into `team_four_factors_nhl.json`.
- `fit_calibration.py` — Fit Platt calibration parameters from ledger outcomes into calibration_params_*.json.
- `fit_calibration_from_daily.py` — Fit Platt calibration parameters from daily ledgers for a model probability column (e.g., `v2c`, `grok`, `gemini`, `gpt`) and write JSON for pipeline/offline use.
- `fit_anchor_offset_calibration.py` — Fit additive-bias (“handicap”) calibration stats from daily ledgers for a probability column (default: `grok`) and break them out by rulebook quadrants (A/B/C/D) vs `kalshi_mid`; writes `chimera_v2c/data/anchor_offset_calibration_<league>_<model>.json` and snapshots prior outputs under `reports/calibration_snapshots/`.
- `nhl_backtest.py` — Read-only ROI/backtest by p bucket from `reports/execution_logs/v2c_plan_log.json` + daily ledgers (one side per game by default; `--all-sides` to include both).
- `nba_backtest.py` — Read-only ROI/backtest by p bucket from `reports/execution_logs/v2c_plan_log.json` + daily ledgers (one side per game by default; `--all-sides` to include both).
- `build_roi_by_bucket_guardrails.py` — Read-only doctrine helper: build per-league `reports/roi_by_bucket_<league>.csv` guardrails from plan logs + daily ledgers (writes `roi_estimate` only when bucket has enough samples; can be used for negative-only bucket blocks or strict positive-only allowlists via `doctrine.require_positive_roi_buckets`).
- `llm_tune_nhl_weights.py` — LLM-assisted suggestions for NHL factor weights (log-only; no auto-write).
- `run_pipeline.py` — Unified runner to refresh/fit/plan/log/backtest across leagues (nba|nhl|nfl). Supports `--llm-injuries` with `--llm-injuries-source espn|moneypuck` (NHL) to apply LLM-derived injury deltas before planning; `--moneypuck-injuries` maintains a canonical MoneyPuck injury snapshot + diff logs.
- `scheduled_injury_plan.py` — Sleep-until-start scheduler (ESPN slate refresh + optional `--llm-injuries` merge; NHL can add `--moneypuck-injuries --llm-injuries-source moneypuck` to run LLM deltas only when the MoneyPuck snapshot changes; can also call run_daily/log_plan/ensure_daily_ledger).
- `backfill_market_proxy_from_odds_history.py` — Append-safe sportsbook backfill using Odds API history. Supports either a fixed per-date snapshot time (`--snapshot-time`) or per-game T-minus (`--minutes-before-start`, e.g. 30 for T-30). Fills blank/`NR` `market_proxy` (no‑vig implied home prob); `kalshi_mid` untouched. Respects locks; use `--allow-locked` to include locked ledgers, and `--overwrite-existing`/`--force` only with explicit intent.
- `align_market_proxy_to_game_start.py` — Align `market_proxy` to each game’s ESPN start timestamp (Odds API history), so comparisons vs `kalshi_mid` captured at the same anchor are time-aligned. Supports `--minutes-before-start` (e.g., 30 for T-30m). Dry-run by default; snapshots before writing; respects lockfiles unless `--force`. Overwriting existing `market_proxy` requires `--overwrite-existing` (explicit human intent only).
- `external_snapshot.py` — Capture timestamped external baselines (Kalshi + books + MoneyPuck) into `reports/market_snapshots/` and optionally fill blank/**`NR`** daily-ledger market cells (`kalshi_mid`, `market_proxy`, and NHL `moneypuck`) append-only; snapshots the daily ledger before writing. By default it snapshots **open** Kalshi markets; use `--kalshi-status settled` (or legacy `closed`) or `--kalshi-status all` (open+settled) when running late.
- `backfill_kalshi_mid_from_candlesticks.py` — Append-safe historical Kalshi mid backfill for games where we did not capture live markets. Uses Kalshi `/markets/candlesticks` to compute `kalshi_mid` at/just before ESPN game start (or `--minutes-before-start`, default T-30m; short lookback fallback) and fills only blank/`NR` cells; retries 429/5xx with backoff; respects lockfiles unless `--force`, snapshots before writing.
- `backfill_moneypuck_pregame.py` — Append-safe NHL backfill of MoneyPuck `preGameMoneyPuckHomeWinPrediction` into daily ledgers as `moneypuck` (fills blank/`NR` only; snapshots the daily ledger before writing). Rich MoneyPuck metadata is stored via `external_snapshot.py` under `reports/market_snapshots/`.
- `ingest_raw_specialist_reports_v2c.py` — Preview-first specialist ingester for raw Gemini/Grok/GPT reports. Parses HELIOS blocks (and legacy `HELIOS_PREDICTION_HEADER` blocks), writes canonical per-game files (`YYYYMMDD_league_away@home_model.txt`), and fills blank/`NR` daily-ledger model cells (append-only; snapshots the daily ledger before writing; respects locks unless `--force`). If a parsed game date doesn’t match any existing daily-ledger row but the filename-inferred `MM-DD` date does (timezone/rollover), it will use the filename date for that matchup. Moves raw files to `reports/specialist_reports/archive/raw_processed/` or `reports/specialist_reports/archive/raw_unparsed/` on apply. Supports both `p_home: 0.52` and variants like `P_HOME (DET): **0.540**` inside `HELIOS_PREDICTION_HEADER` blocks.
- `refresh_model_probs_from_canonicals.py` — Append-safe ledger hydrator: scans canonical specialist reports and fills blank `gemini|grok|gpt` cells using HELIOS `p_home` (preferred) or `p_true`+Winner fallback. Respects lockfiles unless `--force`.
- `add_helios_headers_to_canonical.py` — Canonical report helper: prepends missing HELIOS headers to canonical specialist reports by deriving `Winner` + `p_home` from daily ledgers when safely available (does not touch daily ledgers).
- `normalize_canonical_headers.py` — Canonical report normalizer: canonicalizes team codes in `Game:`/`Winner:` and inserts `p_home` when safely derivable (writes canonical files in place; dry-run by default, `--apply` to write).
- `validate_team_codes.py` — Read-only checker to ensure daily ledgers and canonical specialist reports use normalized team codes via `team_mapper`; exits non-zero on mismatches.

## Dossiers / Research
- `build_dossier.py` — Build per-game dossiers.
- `deep_research.py` — Deep research harness for a given game/date/league.
- `build_llm_packets.py` — Export small, slate-level CSV packets (standings/form, injuries, schedule/fatigue, odds) for a given league/date into `reports/llm_packets/` so LLM specialists can reason from structured tables instead of hallucinating records/injuries/odds. Standings packets include overall/home/road records, last-10 (W/L), and current streak; injuries packets surface per-team deltas from `injury_adjustments.json` or simple status-based heuristics, restricted to teams on the slate; use `--no-odds` to skip generating the odds/markets CSV when you don’t want Kalshi mids in the upload.
- `eval_nba_context_features.py` — R&D: read-only NBA evaluation of whether packet features (form, rest/fatigue, injuries, H2H) improve v2c accuracy. Auto-builds missing packets for each date, fits a logistic adjustment vs baseline, and writes datasets/summaries to `reports/thesis_summaries/`.
- `learn_hybrid_weights.py` — Learn simplex hybrid weights across calibrated models (v2c/grok/gemini/gpt) from the master ledger with date-grouped CV; writes `hybrid_weights_<league>.json` and summaries under `reports/thesis_summaries/`.

## Analysis / Debug
- `analyze_master_ledger.py` — Read-only accuracy/Brier summary off the master ledger.
- `build_scoreboard.py` — Read-only evaluation scoreboard from daily ledgers: writes summary + daily trend + reliability bucket CSVs (and a small Markdown preview) under `reports/thesis_summaries/`.
- `audit_ledger_parity.py` — Read-only parity audit across schedule CSVs (`reports/thesis_summaries/*_schedule_*.csv`), canonical specialist reports (`reports/specialist_reports/*`), daily ledgers, and the derived master ledger; flags phantom/misdated games, score/outcome mismatches, and canonical p_home drift. Use `--skip-master` while repairing schedule↔canonical↔daily parity.
- `audit_ledger_completeness.py` — Read-only audit of blank cells in daily ledgers (v2c/gemini/grok/gpt/kalshi_mid/market_proxy/moneypuck) with CSV outputs under `reports/thesis_summaries/`; can optionally mark *confirmed* missing cells with sentinel `NR` (append-only, respects locks unless `--force`).
- `probe_markets.py` — Quick Kalshi market probe. By default uses the **public** Kalshi API; for live GAME markets you can either:
  - Set `KALSHI_PUBLIC_BASE=https://api.elections.kalshi.com/trade-api/v2` and filter by `series_ticker` (e.g., `KXNBAGAME`), or
  - Use the higher-level helpers in `chimera_v2c/src/market_linker.py` to fetch ESPN matchups and match them to Kalshi tickers, then read home‑implied mids from the resulting `MarketQuote.mid`.
- `analyze_ev_vs_kalshi.py` — Read-only EV vs Kalshi mid and Brier analysis from daily ledgers by date window/league.
- `analyze_scheme_d.py` — Read-only Scheme D analysis (I/J-gated home-favorite fades) from daily ledgers; writes derived rule stats and backtests under `reports/ev_rulebooks/`.
- `analyze_grok_quadrant_consensus.py` — Read-only Grok-vs-Kalshi quadrant breakdown (A/B/C/D) with optional consensus sizing from v2c/gemini/gpt; supports `--confirmer-positive-bucket-only` gating; writes a CSV under `reports/thesis_summaries/`.
- `analyze_rulebook_quadrants.py` — Read-only A/B/C/D + sub-bucket (I/J/K/L/M/N/O/P) EV scan vs Kalshi mid for symmetric “fade/follow” regimes; supports edge-threshold sweeps and can emit a selected rulebook under `reports/ev_rulebooks/` (writes `quadrants_rule_stats.csv` and, in sweep mode, `quadrants_rule_stats_sweep.csv` + `quadrants_rulebook_selected.json`).
- `analyze_positive_quadrant_policy.py` — Read-only quadrant policy simulator: for each model (e.g., `grok|gemini|gpt|market_proxy`) and each league, compute A/B/C/D bucket PnL at a fixed edge threshold and simulate “trade only the model’s positive buckets” (1 unit per model signal; multi-model stacking supported). Writes CSV summaries under `reports/thesis_summaries/`.
- `walkforward_positive_quadrant_policy.py` — Read-only walk-forward (train→test) evaluator for the “positive buckets” policy: for each test day D, learn each model’s positive A/B/C/D buckets on dates < D and trade only those buckets on D (1 unit per model signal; supports multi-model stacking). Default learns per-league buckets when `--league=all` (use `--pool-leagues` to pool) and can pick the edge threshold from `--edge-thresholds` using train-only data. Writes per-day CSV under `reports/thesis_summaries/`.
- `walkforward_agreement_stacking_policy.py` — Read-only walk-forward portfolio rule that filters out model disagreement: learns each model’s positive A/B/C/D buckets on dates < D, then on day D trades only when ≥K models agree on the same side and no model signals the opposite side; sizes by number of agreeing models (optional cap). Supports restricting the policy to a subset of buckets via `--quadrant-buckets` (e.g., `A C`). Also reports a baseline “STACK_ALL” (sum of all model units) for comparison. Writes per-day CSV under `reports/thesis_summaries/`.
- `walkforward_rule_a_ij_tiered_policy.py` — Read-only walk-forward evaluator for a fee-aware, tiered Rule-A sub-bucket policy: when Kalshi is home-fav, trade AWAY only when the primary model triggers `I` (sign flip) or when both primary and confirmer are `J` (no flip), with configurable per-tier contract sizing and maker/taker fee modeling (Oct 2025 quadratic fee schedule). Compares to a baseline “always fade home favorites”. Writes per-day CSV under `reports/thesis_summaries/`.
- `learn_threshold_rulebook_kalshi_mid.py` — Read-only threshold learner: sweep edge thresholds vs `kalshi_mid` for A/B/C/D (optional sub-buckets) and write a selected threshold rulebook JSON to `chimera_v2c/data/threshold_rulebook_kalshi_mid.json` (plus sweep/selected CSVs under `reports/ev_rulebooks/`). Can optionally apply offset calibration from `anchor_offset_calibration_*` files.
- `learn_grok_mid_hybrid.py` — Read-only Grok↔Kalshi-mid hybrid: fits Platt calibration for Grok and learns a shrinkage scalar `alpha` by leave-one-ledger-date-out CV to minimize Brier, using `p_hybrid = p_mid + alpha*(Platt(p_grok)-p_mid)`; writes `chimera_v2c/data/grok_mid_hybrid_<league>.json` and a CV curve CSV under `reports/thesis_summaries/`.
- `walkforward_grok_mid_hybrid.py` — Read-only walk-forward (train→test) evaluator for the Grok↔Kalshi-mid hybrid (Brier-focused): for each ledger date, trains Platt + picks `alpha` on prior days, then evaluates next-day Brier deltas vs `kalshi_mid`; writes per-league daily + summary CSVs under `reports/thesis_summaries/`.
- `walkforward_grok_mid_hybrid_backtest.py` — Read-only walk-forward (train→test) backtest: per ledger date, learns Grok Platt + `alpha` on prior days (default `--alpha-objective brier_cv`, optional `pnl_cv` / `pnl_train`), learns per-bucket edge thresholds `t*` on prior days (A/B/C/D), then evaluates next-day out-of-sample PnL vs `kalshi_mid`. Output includes side-by-side results for `grok_raw`, `grok_platt`, and the `grok_mid_hybrid`; writes a per-day CSV under `reports/thesis_summaries/`.
- `walkforward_grok_mid_hybrid_consensus_backtest.py` — Read-only walk-forward backtest with consensus gating/sizing: learns Grok Platt + `alpha` and per-bucket thresholds on prior days, then evaluates next-day out-of-sample PnL vs `kalshi_mid` for the chosen primary (`raw|platt|hybrid`) and optionally requires confirmers (e.g., `market_proxy`, `v2c`) to agree at the same bucket-specific threshold; writes daily/summary (and optional per-trade audit) CSVs under `reports/thesis_summaries/`.
- `plan_grok_mid_hybrid_trades.py` — Read-only paper trade sheet for a target date: trains Grok Platt + `alpha` and learns A/B/C/D thresholds on dates < target date, then outputs per-game trade recommendations (bucket/side/EV at mid) to `reports/trade_sheets/`.
- `plan_rule_a_ij_tiered_trades.py` — Read-only paper trade sheet for a target date: selects an edge threshold `t` from prior days only and outputs per-game Rule‑A I/J tiered recommendations (primary=I → size `--units-i`; primary=J requires confirmer=J → size `--units-jj`), with optional Kalshi maker/taker fee modeling, to `reports/trade_sheets/`.
- `walkforward_rule_a_unit_policy.py` — Read-only walk-forward backtest: per league and per model, learn fee-aware edge thresholds on buying AWAY at the AWAY ask (`edge_net ≈ (1-p_home) - price_away - fee`) and a confidence-gated unit-sizing policy (taker-only) using Kalshi bid/ask snapshots at a consistent T-minus anchor (e.g., T-30). Writes summary/daily/model-calibration/trades CSVs under `reports/thesis_summaries/`.
- `plan_rule_a_unit_policy_trades.py` — Read-only paper trade sheet for a target date: trains the Rule-A unit policy on dates < target date (no leakage) and outputs per-game recommended contracts (1..cap) using away YES ask (+ optional slippage), including per-model fee-aware edge columns and baseline vote sizing columns for comparison. Writes to `reports/trade_sheets/`.
- `plan_rule_a_hybrid_trades_from_bidask_tminus.py` — Read-only: reconstruct the Rule A “v2c hybrid” per-game contracts and realized PnL for a given date using a T-minus bid/ask snapshot CSV plus per-league vote calibration + eligibility + weak buckets. Writes per-game trades and per-model explanations under `reports/thesis_summaries/`.
- `walkforward_rule_a_vote_calibration.py` — Read-only walk-forward evaluator that learns per-(league,model) vote-delta thresholds (`mid_home - p_model_home >= delta*`) for Rule A under taker/fees (bid/ask snapshots) to maximize net PnL with an ROI guardrail vs the baseline; can also auto-pick whether flip/I signals should be delta-gated; writes summary/daily/model-calibration/trades CSVs under `reports/thesis_summaries/` (filenames include the `--league` tag to avoid overwrites).
- `learn_rule_a_vote_calibration.py` — Read-only trainer that learns per-(league,model) Rule-A vote deltas on a historical window and writes a calibration JSON under `chimera_v2c/data/` for use by `log_rule_a_votes_plan.py --calibration-json ...`.
- `learn_rule_a_weak_buckets.py` — Read-only trainer that learns per-league “weak” `mid_home` buckets (bootstrap lower bound on mean net-per-contract < 0 under a chosen weighted-votes sizing policy) and writes `chimera_v2c/data/rule_a_weak_buckets_<league>.json` for use by `log_rule_a_votes_plan.py --weak-buckets-json ...` (cap sizing in weak buckets; do not hard-exclude unless validated OOS).
- `walkforward_rule_a_model_calibration_backtest.py` — Read-only walk-forward backtest that fits per-model Platt calibration on prior days (<D) and tests whether calibrating model probabilities (e.g., `v2c/grok/gemini/gpt`) improves Rule-A taker PnL/ROI under bid/ask execution; supports optional vote calibration JSON and weak bucket caps JSON; writes summary/daily/params CSVs under `reports/thesis_summaries/`.
- `export_kalshi_fills.py` — Read-only exporter for Kalshi **private-account fills** (executed trades) via the signed private API; writes a CSV under `reports/execution_logs/kalshi_fills/YYYYMMDD/` so operators can reconstruct actual execution when trades were placed manually (requires `KALSHI_API_KEY_ID` + private key via `KALSHI_API_PRIVATE_KEY` or `KALSHI_PRIVATE_KEY_PATH` in `config/env.list`).
- `log_rule_a_votes_plan.py` — Read-only (taker-only) production trade sheet + execution log for Rule-A home-favorite fades using **live** Kalshi quotes: when home is favored (home mid > 0.50) buy away YES at the away ask (+ optional slippage), and size via `--size-mode` (default `blind_plus_votes`) where votes can be gated by both a mid-delta threshold and a **fee-aware edge_net** threshold; supports `blind_plus_weighted_flip2` (configurable `--flip-weight`/`--vote-weight`) and can load per-league per-model thresholds via `--calibration-json`; if `chimera_v2c/data/rule_a_model_eligibility_<league>.json` exists it is auto-loaded (secondary votes count only when at least one primary triggers), or disable via `--no-eligibility`; writes a per-run plan CSV with blank fill columns under `reports/execution_logs/rule_a_votes/YYYYMMDD/` (use `--allow-empty` to write header-only CSVs when no qualifying games).
- `grade_rule_a_votes_plan.py` — Read-only grader for `log_rule_a_votes_plan.py` outputs: joins a plan CSV to daily-ledger outcomes and computes realized gross/fees/net PnL per trade (uses taker fee model when fees are blank); writes a `_results.csv` next to the plan file.
- `simulate_rule_a_votes_gating_from_bidask_tminus.py` — Read-only simulator to compare Rule-A vote gating variants under execution realism using exported Kalshi bid/ask snapshots at a fixed T-minus anchor (includes “keep blind, but tighten extra-units” variants, `I`/`J` gating, and `BLIND_PLUS_WEIGHTED_FLIP2`); supports per-model delta/edge thresholds and slippage stress; writes summary + trade CSVs under `reports/thesis_summaries/`.

### Rule A (Taker) — Current Production Defaults

Rule A is a taker-only “home favorite fade” track; it is separate from the maker-only v2c planner.

- **Default sizing rule (all leagues unless explicitly overridden):** `blind_plus_weighted_flip2` with fee-aware gating (`vote-edge >= 0.0`) and **no delta gate** (delta defaults to 0.00).
- **Per-league calibration (Rec #2):** only apply `--calibration-json` in leagues where walk-forward OOS proves it improves net/ROI.
  - Current status: NHL delta-calibration improves; NBA delta-calibration degrades OOS (keep baseline); NFL unchanged (baseline).
- **Per-league weak bucket caps (Rec #3):** learn weak mid buckets and cap sizing (do not exclude).
  - Learn: `PYTHONPATH=. python chimera_v2c/tools/learn_rule_a_weak_buckets.py --league <league> --start-date 2025-11-19 --end-date YYYY-MM-DD --slippage-cents 1 [--calibration-json chimera_v2c/data/rule_a_vote_calibration_<league>.json]`
  - Apply: pass `--weak-buckets-json chimera_v2c/data/rule_a_weak_buckets_<league>.json` to `log_rule_a_votes_plan.py`.
  - Current learned weak buckets (m30, +1¢, 11/19–12/15): NHL `0.50-0.55` and `0.60-0.65`; NBA none; NFL none.
- **Operator loop:**
  - Refresh baselines: `PYTHONPATH=. python chimera_v2c/tools/external_snapshot.py --league <league> --date YYYY-MM-DD --write-snapshot --apply`
  - Log plan (default; auto-loads per-league eligibility + weak buckets if present): `PYTHONPATH=. python chimera_v2c/tools/log_rule_a_votes_plan.py --league <league> --date YYYY-MM-DD --size-mode blind_plus_weighted_flip2 --slippage-cents 1`
  - Override gates explicitly (optional): `PYTHONPATH=. python chimera_v2c/tools/log_rule_a_votes_plan.py --league <league> --date YYYY-MM-DD --calibration-json chimera_v2c/data/rule_a_vote_calibration_<league>.json --weak-buckets-json chimera_v2c/data/rule_a_weak_buckets_<league>.json`
  - Wrapper (recommended): `PYTHONPATH=. python chimera_v2c/tools/run_rule_a_daily.py plan --date YYYY-MM-DD --leagues nba,nhl,nfl` (auto-loads per-league calibration + weak buckets unless `--no-auto-config`).
  - Optional: append Rule A plan rows into `reports/execution_logs/v2c_plan_log.json` for audit (`strategy=rule_a`): add `--append-v2c-plan-log` when logging.
  - Reconcile execution (Pacific dates): export fills with `PYTHONPATH=. python chimera_v2c/tools/export_kalshi_fills.py --date YYYY-MM-DD`, append to `reports/execution_logs/rule_a_execution_log.csv` via `PYTHONPATH=. python chimera_v2c/tools/append_rule_a_execution_log_from_fills.py --fills-csv <fills.csv>`, then grade with `PYTHONPATH=. python chimera_v2c/tools/grade_rule_a_votes_plan.py --plan-csv <plan.csv>` (auto-uses the execution log if present; prints `[fills]` even if outcomes aren’t final yet).
    - Note: Kalshi executions can appear as either `buy yes` or `sell no` on the away ticker; the Rule A grader treats both as “YES-long” for reconciliation.
  - Once games are final, fill ledger outcomes: `PYTHONPATH=. python chimera_v2c/tools/fill_missing_daily_outcomes.py --date YYYY-MM-DD` then re-run the grader to get realized net PnL.

### Rule A (Taker) — Optional T-minus LLM Automation (Blanks-Only)

This is a stepping-stone workflow: automate GPT/Gemini runs near T-30 only for games where Kalshi currently favors home, then fill daily-ledger blanks and write canonicals for audit.

- Run once (PST “today” implied), dry-run: `PYTHONPATH=. python chimera_v2c/tools/auto_rule_a_tminus_llm.py --leagues nba,nhl --models gpt`
- Apply (writes canonicals + fills daily ledger blanks via the ingester): `PYTHONPATH=. python chimera_v2c/tools/auto_rule_a_tminus_llm.py --leagues nba,nhl --models gpt --apply`
- Scheduler pattern: run the same command every ~60s with the default `--min-minutes-to-start 29 --max-minutes-to-start 31` window, or use built-in polling: `PYTHONPATH=. python chimera_v2c/tools/auto_rule_a_tminus_llm.py --leagues nba,nhl --models gpt,gemini --apply --poll-seconds 60`.
- Model selection: defaults are `--gpt-model gpt-5.2-pro` and `--gemini-model gemini-3.0-pro` with automatic fallbacks (`--gpt-model-fallback gpt-4o-mini`, `--gemini-model-fallback gemini-2.0-flash`) if the primary model errors.
- `simulate_rule_a_taker_slippage.py` — Read-only execution simulator for Rule A that applies taker fees and a fixed slippage (e.g. +1–2¢) vs the away mid price, with both “separate orders per model” and “aggregated per game” sizing variants. Writes summary CSV under `reports/thesis_summaries/`.
- `simulate_rule_a_from_bidask_tminus.py` — Read-only Rule A simulator that uses exported Kalshi YES bid/ask snapshots at a consistent T-minus anchor (e.g. T-30), executes fades at the away YES ask (+ optional slippage), and slices results by league and model. Writes summary CSV under `reports/thesis_summaries/`.
- `export_kalshi_bidask_tminus.py` — Read-only exporter that pulls Kalshi YES bid/ask candlestick closes at a consistent T-minus timestamp (default T-30) for each game in the daily ledgers and writes a snapshot CSV under `reports/market_snapshots/`.
- `audit_rule_a_bidask_samples.py` — Read-only strict spot-checker that hand-audits a random sample of Rule A-qualifying games end-to-end (daily ledger ↔ Kalshi candlesticks ↔ ESPN start time ↔ Odds API market_proxy ↔ canonical specialist reports). Stops at the first discrepancy.
- `validate_rule_a_bidask_suite.py` — Read-only validation suite for Rule A using T-minus bid/ask snapshots; produces out-of-sample split, anchor sensitivity, mid bucket breakdown, and fill-rate stress tables under `reports/thesis_summaries/`.
- `build_rule_a_bucket_filter.py` — Read-only helper that converts the suite mid-bucket breakdown into a concrete “filtered buckets” policy (cut any buckets with negative overall net PnL) and writes a policy summary CSV under `reports/thesis_summaries/`.
- `online_grok_mid_hybrid_walkthrough.py` — Read-only online learning curve (game-by-game): re-fits Grok Platt + selects `alpha` after each graded game and reports whether hybrid Brier/PnL improves as n grows; writes a walkthrough CSV under `reports/thesis_summaries/`.
- `update_moneypuck_injuries_nhl.py` — Fetch MoneyPuck’s public `current_injuries.csv`, write canonical `chimera_v2c/data/moneypuck_injuries_nhl.{json,csv}`, and emit a slate-filtered LLM digest; writes diffs under `reports/alerts/moneypuck_injuries/` when changed.
- `watch_moneypuck_injuries_nhl.py` — Log-only poller that checks MoneyPuck injuries every N minutes and prints an alert + writes diffs on change (no auto-trigger).
- `analyze_home_rich_sweet_spots.py` — Read-only sweep over edge thresholds for “Kalshi home favorite, model says home is rich → fade home” and writes per-model curves + sweet-spot summary under `reports/thesis_summaries/`.
- `eval_positive_bucket_policy.py` — Read-only simulator: build per-model “positive p_yes buckets” from a training window and simulate a target slate trading only those buckets (compares v2c/grok/gemini/gpt/market_proxy/moneypuck vs Kalshi mid).

**Current Rule A sizing defaults (production bias)**
- NHL uses `chimera_v2c/data/rule_a_vote_calibration_nhl.json` with `base_units: 0` (no blind NHL) and a restricted model set (`market_proxy`, `grok`, `gemini`). NHL trades require at least one qualifying vote/flip (fee-aware edge gate + per-model deltas) before taking any position.

## Archived / Legacy
The following legacy tools were intentionally removed from the active v2c repo (see git history if needed) and should not be used for production:
- `analyze_recent_performance.py`
- `apply_llm_injuries.py`
- `backfill_daily_ledger_from_plan.py`
- `build_game_master_ledger.py`
- `fill_master_scores.py`
- `inspect_game_master_ledger.py`
- `organize_specialist_reports.py`
- `parse_specialist_batch.py`
- `process_raw_specialist_reports.py`
- `rebuild_specialist_ledger.py`
- `select_canonical_specialist_versions.py`
- `split_specialist_ledger_by_league.py`
- `prepare_nhl_ratings.py`

If a legacy tool is needed, retrieve it intentionally from git history and document it here with clear overwrite safeguards.
