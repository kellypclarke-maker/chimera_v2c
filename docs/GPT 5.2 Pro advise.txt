You’re thinking about this the right way: **for a solo hobbyist, the highest-ROI path is almost never “build a full MoneyPuck from scratch.”** MoneyPuck already has years of model + feature engineering behind it (and they disclose weights, training window, and performance), so duplicating that is a huge lift. ([MoneyPuck][1])

### What I’d do in your situation (best path forward)

**Shift your system from “invent p_true” → “detect mispricing + calibrate.”** Concretely:

1. **Baseline = sportsbook consensus no‑vig**

* Treat **de‑vigged multi-book moneyline** as your default “fair” probability (your p_true *proxy*).
* This is usually the strongest, most information-efficient signal you can get without building a full model.

2. **Use MoneyPuck as a *feature / second opinion*, not the truth**

* MoneyPuck’s pregame model is explicitly built as a win-prob predictor and is explainable by components (ability-to-win, scoring chances, goaltending) with weights like **54% scoring chances, 29% goaltending, 17% ability**. ([MoneyPuck][1])
* They also publish season-level results (e.g., log loss figures), which is rare and useful for benchmarking. ([MoneyPuck][1])
* But because it’s public, **it’s unlikely to beat sharp sportsbook consensus consistently** on its own.

3. **Your edge target = “Kalshi lag / microstructure,” not “out-model Vegas”**

* If you want to beat Kalshi, the most plausible solo edge is:

  * **Kalshi midpoint deviates from sportsbook consensus** (especially when liquidity is thin or the market is slow to react).
  * **Late-breaking info** (confirmed goalie, scratches) that books price quickly but Kalshi may price slower.
* Also: Kalshi explicitly notes trading involves fees/risk and info is “AS IS,” which matters for sizing and thresholds. ([Kalshi][2])

4. **Keep the LLM directive—but change its job**
   Don’t have Grok/Gemini/GPT “create p_true from scratch.” Instead use them to:

* pull/verify **starter goalie status + key injury certainty**
* compute **ptcs (data quality / confidence)**
* propose **bounded deltas** (small adjustments)
* output clean structured headers (your v8.x format already enforces this). 

5. **Build a simple meta-model (optional, but very doable)**
   If you want *some* “v2c” progress without reinventing the wheel:

* Make a tiny model whose inputs are just:

  * `p_books_no_vig`
  * `p_moneypuck`
  * `rest/B2B`
  * `goalie_confirmed_flag`
  * `ptcs`
* Fit a logistic regression (or isotonic calibration) to reduce Brier/log loss.
  This is **orders of magnitude easier** than building a full xG + player-value engine.

---

## What you should spend effort on (in priority order)

### A) Data pipeline + backtest harness (this is the whole game)

Use an odds provider to capture **time-aligned snapshots**:

* The Odds API explicitly supports NHL odds + has **historical odds** (featured markets back to mid‑2020) which is perfect for backtests. ([the-odds-api.com][3])
  Record for every game at **the same timestamp**:
* Kalshi midpoint (or best bid/ask midpoint)
* sportsbook consensus no‑vig
* MoneyPuck probability
* your LLM output + ptcs
* final result

Then measure:

* Brier score, log loss
* calibration curves
* “edge realized” vs Kalshi after fees/slippage

### B) Edge rules (simple and realistic)

* Only trade when `|p_books_no_vig - p_kalshi_mid|` exceeds a threshold that **increases when ptcs is low**.
* This aligns with your earlier ptcs idea: low-quality info → hug the market more.

### C) Regulatory/availability risk (don’t ignore)

Kalshi’s sports contracts are in active legal/regulatory conflict in multiple states (e.g., Massachusetts seeking an injunction). That creates platform/market-availability risk for any long-term system you build around it. ([Reuters][4])
At the same time, the NHL itself announced deals with Kalshi/Polymarket, which suggests the category is gaining legitimacy and attention. ([ESPN.com][5])
Net: **great for opportunity, but plan for disruption**.

---

## Direct answer: analyze vs Kalshi, or keep building custom model?

**Do both, but heavily weighted toward “analyze & exploit mispricing.”**

* **80%**: build the *comparison + alert + evaluation* system (books + MoneyPuck + Kalshi)
* **20%**: keep refining the directive + ptcs + small calibrated adjustment layer
* **0–10%** (only if you enjoy it): “true from-scratch v2c” beyond a lightweight meta-model

If after ~200–500 bets (or paper trades) you can’t beat a “books no‑vig baseline” on Brier/log loss **and** can’t find stable Kalshi mispricings net of fees, **that’s your signal to stop expanding complexity**.

If you want, I can sketch a minimal logging schema (columns + timestamps) and the exact metrics to compute so you can quantify whether “MoneyPuck vs books vs your LLM+ptcs overlay” actually improves calibration.

[1]: https://moneypuck.com/about.htm "MoneyPuck.com -About and How it Works"
[2]: https://kalshi.com/sports/hockey/NHL "NHL Hockey Odds & Predictions 2025"
[3]: https://the-odds-api.com/sports/nhl-odds.html "NHL Odds API | The Odds API"
[4]: https://www.reuters.com/legal/government/massachusetts-seeks-block-kalshi-operating-sports-prediction-market-2025-12-09/ "Massachusetts asks judge to block Kalshi from operating sports-prediction market | Reuters"
[5]: https://www.espn.com/nhl/story/_/id/46683244/nhl-inks-deal-prediction-markets-kalshi-polymarket "NHL inks deal with prediction markets Kalshi and Polymarket - ESPN"
